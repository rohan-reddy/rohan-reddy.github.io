---
title: "About"
image: images/profile.jpg
about:
  template: jolla
  links:
    - icon: linkedin
      text: LinkedIn
      href: https://www.linkedin.com/in/rohan-reddy-bba12a111/
    - icon: github
      text: Github
      href: https://github.com/rohan-reddy

---
:::{style="text-align: left"}
#### About me

I grew up in Chapel Hill, North Carolina. I originally moved to New York over a decade ago to attend college at NYU, where I studied finance and computer science, and I've pretty much been here ever since. After graduation, I worked at Amazon for a little over 4 years in their demand forecasting group, where I worked on both production machine learning systems and research projects. In particular, I contributed to [research on hierarchical forecasting](https://www.sciencedirect.com/science/article/pii/S0169207023000432) that my team presented at NeurIPS in 2021 and subsequently published in the International Journal of Forecasting. In 2023, I took a sabbatical to explore my interests, which included math and graphics rendering. The following year, I ended up enrolling in a second bachelor's degree in mathematics from Indiana University East, which I recently completed (December 2025). Now, I'm studying all things GPU-related and keeping an eye out for roles that are aligned with my interests. If you have something that could be a good fit, please feel free to reach out to me on LinkedIn or directly at rreddy.nyc@gmail.com. 

Apart from work, I like to take photos whenever I get the chance to travel somewhere interesting. I try to experiment and get a little bit better each time. In particular, I photograph a lot of animals and landscapes. If you're interested, you can check some of them out at my [photography site](https://rohanreddy.myportfolio.com). I also enjoy playing tennis, swimming, lifting, playing the piano, and baking. 

#### About this blog
Initially, I'm focusing on learning as much as possible about GPU architecture from a software engineer's perspective, and optimizing performance of GPU kernels for common AI workloads. Next, I'm thinking of exploring topics like distributed communication across multiple GPUs (e.g. NCCL), low-precision quantization, and compiler-level abstractions (e.g. Triton, MLIR). If you have suggestions on learning/research directions or any feedback for me, I love to hear them - please email me directly at rreddy.nyc@gmail.com.  
:::